# ğŸ“˜ ArEEG: Arabic Inner Speech EEG Dataset & Decoding Pipeline

Welcome to the official repository for **our undergraduate thesis project at The American University in Cairo** , focusing on decoding Arabic imagined speech (inner speech) using EEG signals.

This repository includes all code, experiments, documentation, and models created as part of our thesis.

# ğŸ“¦ Dataset used:
ğŸ‘‰ ArEEG: An Open-Access Arabic Inner Speech EEG Dataset

ğŸ”— https://github.com/Eslam21/ArEEG-an-Open-Access-Arabic-Inner-Speech-EEG-Dataset

# ğŸš¨ **Why This Project Matters**

Individuals with **ALS**, **Locked-in Syndrome**, or severe paralysis often lose the ability to speak.
Brainâ€“Computer Interfaces (BCIs) offer a way to restore communication by decoding the **silent inner voice** directly from the brain.

However, major challenges exist:

* ğŸ‡¬ğŸ‡§ **Almost all existing datasets are English-only**
* ğŸ”Š **EEG signals are noisy and non-stationary**
* ğŸ§  **Models struggle to generalize across subjects**
* ğŸ‡ªğŸ‡¬ **Very limited research exists for Arabic imagined speech**

âœ¨ This makes **ArEEG the first open-access Arabic inner speech EEG dataset**, enabling more inclusive BCI research.

---

# ğŸ”‘ **Key Features of Our Thesis**

## ğŸ§  **EEG Imagined Speech Decoding**

We develop pipelines for preprocessing, feature extraction, and deep-learning-based decoding.

---

## ğŸ“š **Five Arabic Commands**

**Up**, **Down**, **Left**, **Right**, **Select**

---

## ğŸ— **Complete Processing Pipeline**

* Preprocessing (filters, ICA, re-referencing)
* Feature extraction (P300, CSP Features, Riemannian features, Time-Frequency, Spatial Featurew)
* Deep learning models (CNN, LSTM, Transformers) 
* Evaluation (cross-subject & within-subject) 

---

## ğŸ§ª **Reproducible Experiments**

All code will be published here as the thesis progresses.

---

# ğŸ‘©â€ğŸ’» **Contributors**

* Farah Badawi
* Jana Aboelsoud
* Nadine Karam
* Nour Salem

Mentor: **Dr. Seif Eldawlatly**, Department of Data Science, AUC
